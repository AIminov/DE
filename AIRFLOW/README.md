
Статью подготовил: Шустиков Владимир. (https://t.me/Shust_DE)

## Напутственные слова перед изучением материала

**!!!Сюда стоит лезть, после изучения курсов по Python!!!**

Данная статья охватывает основы работы с оркестратором AirFlow. Рассмотрим кратко теорию которую спрашивают достаточно часто, посмотрим как локально развернуть AirFlow с помощью docker-compose и рассмотрим простой пример одного из тестовых заданий, который охватывает достаточно большие возможности AirFlow.

Как говорил мой дед: "Я твой дед!". Вы можете спросить, "А к чему ты это написал?", а я вам отвечу "Хз. Живите теперь с этим!"

Приятного погружения.

-----------------
<h1 style="text-align: center;">AIRFLOW</h1>

Возьмём определение с [официального репозитория AirFlow](https://github.com/apache/airflow).

**AirFlow** — это платформа для программирования, планирования и мониторинга рабочих процессов.

А в общем и целом нужно запомнить, что AirFlow это **оркестратор** (не ELT-инстремент), в котором есть возможность прописывать ETL процессы, на языке Python. Каждый такой процес представляет собой DAG, состоящий из определённых задач, на сленге правильно говорить тасок.

<p align="center">
    <img src="./../png/airflow_logo.png" alt="AirFlow"/>
</p>

## DAG

DAG(Directed Acyclic Graph, направленный ациклический граф) представлет из себя набор такос идущих последовательно друг за дружкой либо параллельно и которые нельзя зациклить по кругу, т.е. своего рода строится прямолинейный конвеер обработки данных.

<p align="center">
    <img src="./../png/af_dag.png" alt="AirFlow" />
</p>

## Архитектура AirFlow

AirFlow состоит из трёх основных, взаимосвязанных компонентов:

* Планировщик AirFlow(scheduler)
* Исполнитель(Executor)
* Воркеры (workers)
* Веб-сервер AirFlow


<p align="center">
    <img src="./../png/af_arfitecture.png" alt="AirFlow" />
</p>

### Задачи планировщика

- Анализ графа;
- Проверка параметра **scheduler_interval**, который определяет частоту выполнения DAG;
- Планирование очереди графов.

### Задачи Исполнителя

- Запуск задач; 
- Распеделение задач между воркерами.

### Задачи воркеров

- Получает задачи от исполнителя;
- Отвечает за полное выполнение задач.

### Задачи Веб-сервера AirFlow

- Визуализация DAG'а, который проанализировал планировщик;
- Предоставлять интерфейс пользователю для отслеживания работы DAG.

## Операторы AirFlow

Как вам уже известно конвеер обработки является направленныйм ацикличным графом, в свою очередь DAG состит из определённых задач, которые определяются **операторами**. 

В AirFlow существует множество операторов, с из полным списком можно ознакомиться [здесь](https://airflow.apache.org/docs/apache-airflow-providers/operators-and-hooks-ref/index.html)

Вот примеры, часто свтечаемых операторов с которыми мы познакомимся в примере ниже:

* PythonOperator
* BashOperator
* PostgresOperator

## Передача данных между задачами.
 
Существует 2 метода передачи данных между тасками в AirFlow:

1. Механизм XCom;
2. сохраниение данных в хранилищах.

### Механизм XCom

XCom - позволяется обмениться сообщениями между задачами. Предназначен он исключительно для **небольших данных**. 

Согласно документации в замисимости от используемой базой данных метаинформации:

* SQLLite - до 2х Гб.
* PostreSQL - до 1 Гб.
* MySQL - до 64 Кб.

**Запомните** XCom можно использовать для передачи небольших объемов данных, например значение агрегации, колличества строк в файле, даже можно небольшой файл передать, но в остальных случаях используйте внешние решения для хранения данных, как пример, сохраняйте все в каnалог tmp и потом забирайте данные от туда.

Определяется Xcom 2мя способами:

* с помощью команд **xcom_push** и **xcom_pull**
* с помощью **Taskflow API** (декоратор **@task**)


---------
## Пример тестового задания

Необходимо написать DAG который будет выполнять следующие задачи:
 
1. С помощью PythonOperator необходимо сгенерировать тестовые данные и записать их в файл в каталог /tmp/data.csv ( для простоты можно взять 2 колонки id, value )
2. С помощью BashOperator переместить файл в каталог /tmp/processed_data
3. C помощью PythonOperator нужно загрузить данные из файла в таблицу в Postgres ( таблицу можно предварительно создать )
4. После записи данных в таблицу последним таском выведите в логах сообщение о количестве загруженных данных.
 
С помощью XCom необходимо:
 
Передать путь до файла из п.1 в оператор в п.2.
Передать количество записей из п.3 в п.4