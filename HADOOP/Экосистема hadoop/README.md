## Куратор раздела

<img align="left" width="200" src="../../png/amp.jpg" />

**Подвальный Артем** 

   [Telegram канал](https://t.me/dataengineerlab)

Хочешь перейти в дата-инженерию, но не знаешь с чего начать? Пиши -  составим резюме, продумаем твое развитие https://dataengineers.pro/mentors/artyompodvalny 

Хочешь улучшить текущий раздел, внести недостающее или поправить формулировку? Предлагай PR и тегай [@Artemlin6231](https://github.com/Artemlin6231)

## Немного об этой главе
Экосистема hadoop разворачивается в большей части компаний при работой с BigData, знание её компонентов также важно как и самого hadoop

Приятного изучения)




## Компоненты экосистемы Hadoop


<p align="center">
    <img src="../../png/yarn_map_reduce.jpg" alt="map_reduce"/>
</p>

### HDFS (Hadoop Distributed File System)
Распределённая файловая система, обеспечивающая надёжное и масштабируемое хранение больших объёмов данных на кластере из обычных серверов.

### YARN (Yet Another Resource Negotiator)
Слой управления ресурсами и планирования заданий. Позволяет эффективно распределять ресурсы между различными приложениями, такими как MapReduce, Spark, Tez и другими.

### MapReduce и Spark
Движки для распределённой обработки данных:
- **MapReduce** — классическая модель обработки больших данных.
- **Spark** — более современный, быстрый и гибкий фреймворк для распределённых вычислений в памяти.

### Дополнительные инструменты
- **Hive** — SQL-подобный интерфейс для анализа данных в Hadoop.
- **Pig** — язык потоков данных, простой в использовании для анализа.
- **HBase** — распределённая колонко-ориентированная база данных.
- **Oozie** — планировщик рабочих процессов (workflow scheduler).
- **ZooKeeper** — служба координации и управления распределёнными приложениями.

---

## MapReduce

### Зачем нужен MapReduce?

В условиях стремительного роста объёмов информации традиционные методы обработки данных перестали справляться с поставленными задачами. Компании столкнулись с необходимостью обрабатывать терабайты и даже петабайты данных ежедневно. Именно в ответ на этот вызов и появился MapReduce — революционный подход, ставший фундаментом для распределённых вычислений в рамках экосистемы Hadoop.

### Как работает MapReduce?

MapReduce — это способ обработки больших объёмов данных за счёт разбиения задачи на мелкие подзадачи, которые параллельно обрабатываются на разных машинах в кластере.

#### Этапы обработки:

1. **Input**  
   На вход подаётся большой массив данных: текст, логи, последовательности ДНК и т.д.
2. **Splitting**  
   Данные делятся на фрагменты, которые обрабатываются независимо.
3. **Mapping**  
   Каждый фрагмент проходит через функцию `map`, которая превращает данные в пары «ключ — значение».  
4. **Shuffling**  
Все одинаковые ключи группируются:
5. **Reducing**  
К каждой группе применяется функция `reduce`, которая агрегирует значения.  
Пример:
