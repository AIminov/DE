# Реальные задачи на работе


### КЕЙС Витрина данных

Витрина данных – это просто табличка, которая уже сто раз отфильтрована, где-то очищена от лишних данных. Но у витрины данных могут быть разные источники. Например у меня витрина собиралась из данных по дебетовым картам, кредитным, ипотекам, вкладам и так далее. Реально много разных источников таблиц. Каждый источник обновляет у себя данные в разное время. У кого-то сегодня данные готовы за вчера, а где-то только за позавчера. 

Поэтому если мы будет запускать расчет витрины с одной датой за вчера (Т-1), то по каким-то источникам мы прочитаем свежие данные, а по каким-то будет 0 строк (данные в источнике еще не добавились). Че делать?

Я начал логировать в отдельную таблицу последнюю дату загрузки данных по каждому продукту во время расчета витрины. И при следующем запуске, мой скрипт ходит в таблицу с метаданными и читает для каждого продукта (карты, кредиты, вклады и т.д.) свою максимальную дату. Очевидно, что искать максимальную дату в такой таблице это очень быстро. И потом каждый продукт уже грузится со своей датой. Т.е. если например источник по вкладам умер и больше не передает нам нисколько строк, то витрина без него будет считаться. А как только он ожил, то скрипт запустит расчет от крайней даты загрузки. Надеюсь я вас не запутал. Кейс самый настоящий коммерческий. Падения источников случаются и хорошо бы быть готовым к такому.


<!-- Сборка витрины на dbt для аналитиков 

Миграция из ГП в ГП 700Гб через jdbc и через pxf.

Из источника прилетает строка с //u0000, которую нельзя кастануть в json. Надо исправлять это на уровне Спарка

Миграция 700Гб из ГП в ГП таблицы через pxf external table. Также через jdbc по сегментам. 
Миграция из AWS в GP с помощью Spark Scala.
CI CD на Github Actions (проверка изменений в файлах с Github Summary)
Переписывание API на питоне на ГринПлам с использованием Метадаты

есть папка 1000 файлов
названы по разному
Мне надо загрузить это все в БД
Взять все - слишком много
Надо брать частями - вопрос как это сделать? --> -->
